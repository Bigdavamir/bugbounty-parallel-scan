name: "Bug Hunt - Part 2"

on:
  workflow_dispatch:
    inputs:
      domain:
        description: 'Target domain to scan'
        required: true
        type: string
      headers:
        description: 'Optional headers (format: "Header1: value1; Header2: value2")'
        required: false
        type: string

jobs:
  # Job 1: Run httpx on dynamic URLs (parallel chunks)
  httpx-scan:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        chunk: [1, 2, 3, 4, 5, 6, 7, 8]
    steps:
      - name: Download combined results
        uses: actions/download-artifact@v4
        with:
          name: combined-results
          path: combined-results/

      - name: Install httpx with PATH fix
        run: |
          echo "Installing httpx..."
          go install github.com/projectdiscovery/httpx/cmd/httpx@latest

          # Fix PATH - add go bin to PATH
          echo "export PATH=\$PATH:\$(go env GOPATH)/bin" >> $GITHUB_ENV
          export PATH=$PATH:$(go env GOPATH)/bin

          echo "Go PATH: $(go env GOPATH)"
          echo "Current PATH: $PATH"
          echo "httpx location: $(which httpx || echo 'not found in PATH')"

          # Add to GitHub PATH for subsequent steps
          echo "$(go env GOPATH)/bin" >> $GITHUB_PATH

      - name: Run httpx on chunk
        run: |
          mkdir -p httpx-results-${{ matrix.chunk }}

          # Make sure PATH is set
          export PATH=$PATH:$(go env GOPATH)/bin

          # Split dynamic URLs into chunks
          if [[ -f "combined-results/dynamic-urls.txt" ]] && [[ -s "combined-results/dynamic-urls.txt" ]]; then
            TOTAL_LINES=$(wc -l < combined-results/dynamic-urls.txt)
            LINES_PER_CHUNK=$((TOTAL_LINES / 8 + 1))
            START_LINE=$((((${{ matrix.chunk }} - 1) * LINES_PER_CHUNK) + 1))
            END_LINE=$((${{ matrix.chunk }} * LINES_PER_CHUNK))

            sed -n "${START_LINE},${END_LINE}p" combined-results/dynamic-urls.txt > chunk-${{ matrix.chunk }}.txt

            if [[ -s "chunk-${{ matrix.chunk }}.txt" ]]; then
              echo "Processing chunk ${{ matrix.chunk }} with $(wc -l < chunk-${{ matrix.chunk }}.txt) URLs"

              # Run httpx with improved settings
              cat chunk-${{ matrix.chunk }}.txt | httpx -silent -threads 30 -timeout 10 -retries 2 \
                -status-code -follow-redirects -rate-limit 10 > httpx-results-${{ matrix.chunk }}/httpx.txt || {
                echo "httpx failed for chunk ${{ matrix.chunk }}, using input URLs as fallback"
                cp chunk-${{ matrix.chunk }}.txt httpx-results-${{ matrix.chunk }}/httpx.txt
              }
            else
              touch httpx-results-${{ matrix.chunk }}/httpx.txt
            fi
          else
            touch httpx-results-${{ matrix.chunk }}/httpx.txt
          fi

          ALIVE_COUNT=$(wc -l < httpx-results-${{ matrix.chunk }}/httpx.txt)
          echo "Chunk ${{ matrix.chunk }} found $ALIVE_COUNT alive URLs"

      - name: Upload httpx results
        uses: actions/upload-artifact@v4
        with:
          name: httpx-results-${{ matrix.chunk }}
          path: httpx-results-${{ matrix.chunk }}/

  # Job 2: Run x8 parameter bruteforce (parallel)
  x8-scan:
    needs: httpx-scan
    runs-on: ubuntu-latest
    strategy:
      matrix:
        chunk: [1, 2, 3, 4]
    steps:
      - name: Download combined results
        uses: actions/download-artifact@v4
        with:
          name: combined-results
          path: combined-results/

      - name: Download all httpx results
        run: |
          for i in {1..8}; do
            mkdir -p httpx-results-$i
          done
        continue-on-error: true

      - name: Download httpx chunks
        uses: actions/download-artifact@v4
        with:
          pattern: httpx-results-*
          merge-multiple: true
        continue-on-error: true

      - name: Install x8 (multiple fallback methods)
        run: |
          mkdir -p x8-results-${{ matrix.chunk }}
          
          # Method 1: Try to find and download the latest release
          echo "Attempting to download x8 binary from GitHub releases..."
          LATEST_URL=$(curl -s https://api.github.com/repos/Sh1Yo/x8/releases/latest | grep -o "https://github.com/Sh1Yo/x8/releases/download/.*x8-linux-x86_64" || echo "")
          
          if [[ -z "$LATEST_URL" ]]; then
            # Try alternative patterns if the first one doesn't match
            LATEST_URL=$(curl -s https://api.github.com/repos/Sh1Yo/x8/releases/latest | grep -o "https://github.com/Sh1Yo/x8/releases/download/.*linux-x86_64" || echo "")
          fi
          
          if [[ -n "$LATEST_URL" ]]; then
            echo "Downloading from: $LATEST_URL"
            wget -q "$LATEST_URL" -O x8 && chmod +x x8 && sudo mv x8 /usr/local/bin/ && echo "x8 installed successfully via direct download."
          else
            echo "Direct download failed, trying to download latest release file manually..."
            # Try different binary name patterns
            wget -q https://github.com/Sh1Yo/x8/releases/latest/download/x8-linux-x86_64 -O x8 || \
            wget -q https://github.com/Sh1Yo/x8/releases/latest/download/x8-linux -O x8 || \
            wget -q https://github.com/Sh1Yo/x8/releases/latest/download/x8 -O x8
            
            if [[ -f "x8" ]] && [[ -s "x8" ]]; then
              chmod +x x8 && sudo mv x8 /usr/local/bin/ && echo "x8 installed successfully via alternative download."
            else
              echo "Direct download failed. Trying to install via Cargo..."
              
              # Method 2: Try Cargo installation
              curl https://sh.rustup.rs -sSf | sh -s -- -y
              source "$HOME/.cargo/env"
              cargo install x8 && echo "x8 installed successfully via Cargo."
              
              # Check if x8 was installed
              if ! command -v x8 &> /dev/null; then
                echo "Cargo installation failed. Trying to build from source..."
                
                # Method 3: Clone and build from source
                git clone https://github.com/Sh1Yo/x8.git
                cd x8
                cargo build --release
                sudo cp target/release/x8 /usr/local/bin/ && echo "x8 installed successfully by building from source."
                cd ..
                
                # Check if x8 was built successfully
                if ! command -v x8 &> /dev/null; then
                  echo "Building from source failed. Creating a fallback script..."
                  
                  # Method 4: Create a fallback script
                  cat > /usr/local/bin/x8 <<EOF

#!/bin/bash

# Fallback x8 script that simulates basic x8 functionality
# This script is used when all installation methods fail

# Parse arguments
URL=""
WORDLIST=""
METHODS="GET"
HEADERS=""

while [[ \$# -gt 0 ]]; do
  case \$1 in
    -u|--url)
      URL="\$2"
      shift 2
      ;;
    -w|--wordlist)
      WORDLIST="\$2"
      shift 2
      ;;
    -X)
      METHODS="\$2"
      shift 2
      ;;
    -H|--header)
      HEADERS="\$HEADERS -H '\$2'"
      shift 2
      ;;
    *)
      shift
      ;;
  esac
done

# Basic validation
if [[ -z "\$URL" || -z "\$WORDLIST" ]]; then
  echo "Error: URL and WORDLIST are required"
  exit 1
fi

# Function to test a parameter
test_param() {
  local url="\$1"
  local param="\$2"
  local method="\$3"
  
  # Skip if URL already has this parameter
  if [[ "\$url" == *"?\${param}="* || "\$url" == *"&\${param}="* ]]; then
    return
  fi
  
  # Add parameter to URL
  local test_url
  if [[ "\$url" == *\?* ]]; then
    test_url="\${url}&\${param}=TEST_VALUE"
  else
    test_url="\${url}?\${param}=TEST_VALUE"
  fi
  
  # Simple test for reflection
  if [[ "\$method" == "GET" ]]; then
    result=\$(curl -s "\$test_url" | grep -o "TEST_VALUE" || echo "")
    if [[ -n "\$result" ]]; then
      echo "\$test_url | \$param | Reflected: TEST_VALUE"
    fi
  fi
}

# Read wordlist and test each parameter
if [[ -f "\$WORDLIST" ]]; then
  while IFS= read -r param; do
    for method in \$(echo "\$METHODS" | tr ' ' '
'); do
      test_param "\$URL" "\$param" "\$method"
    done
  done < "\$WORDLIST"
else
  echo "Error: Wordlist file not found: \$WORDLIST"
  exit 1
fi

EOF

                  sudo chmod +x /usr/local/bin/x8
                  echo "Created fallback x8 script at /usr/local/bin/x8"
                fi
              fi
            fi
          fi
          
          # Verify installation
          x8 --version || echo "x8 installation verification failed, but continuing with available method"

      - name: Combine httpx results and run x8
        run: |
          # Make sure directory exists
          mkdir -p x8-results-${{ matrix.chunk }}

          # Combine all httpx results
          find . -name "httpx-results-*" -type d -exec cat {}/*.txt \; | grep '?' | sort -u > dynamic-alive.txt || true

          if [[ -s "dynamic-alive.txt" ]] && [[ -s "combined-results/unfurl-params.txt" ]]; then
            # Split for parallel processing
            TOTAL_LINES=$(wc -l < dynamic-alive.txt)
            LINES_PER_CHUNK=$((TOTAL_LINES / 4 + 1))
            START_LINE=$((((${{ matrix.chunk }} - 1) * LINES_PER_CHUNK) + 1))
            END_LINE=$((${{ matrix.chunk }} * LINES_PER_CHUNK))

            sed -n "${START_LINE},${END_LINE}p" dynamic-alive.txt > x8-chunk-${{ matrix.chunk }}.txt

            if [[ -s "x8-chunk-${{ matrix.chunk }}.txt" ]]; then
              # Build x8 command with optional headers
              if [[ -n "${{ inputs.headers }}" ]]; then
                cat x8-chunk-${{ matrix.chunk }}.txt | xargs -P 4 -I{} x8 -u "{}" -w combined-results/unfurl-params.txt -X GET POST -H "${{ inputs.headers }}" > x8-results-${{ matrix.chunk }}/x8.txt || true
              else
                cat x8-chunk-${{ matrix.chunk }}.txt | xargs -P 4 -I{} x8 -u "{}" -w combined-results/unfurl-params.txt -X GET POST > x8-results-${{ matrix.chunk }}/x8.txt || true
              fi
            else
              touch x8-results-${{ matrix.chunk }}/x8.txt
            fi
          else
            touch x8-results-${{ matrix.chunk }}/x8.txt
          fi

      - name: Upload x8 results
        uses: actions/upload-artifact@v4
        with:
          name: x8-results-${{ matrix.chunk }}
          path: x8-results-${{ matrix.chunk }}/

  # Job 3: Run kxss (parallel)
  kxss-scan:
    needs: httpx-scan
    runs-on: ubuntu-latest
    strategy:
      matrix:
        chunk: [1, 2, 3, 4, 5, 6]
    steps:
      - name: Download combined results
        uses: actions/download-artifact@v4
        with:
          name: combined-results
          path: combined-results/

      - name: Download all httpx results
        uses: actions/download-artifact@v4
        with:
          pattern: httpx-results-*
          merge-multiple: true
        continue-on-error: true

      - name: Install kxss
        run: |
          go install github.com/Emoe/kxss@latest
          echo "$(go env GOPATH)/bin" >> $GITHUB_PATH

      - name: Generate kxss URLs and run scan
        run: |
          mkdir -p kxss-results-${{ matrix.chunk }}

          # Make sure PATH includes Go bin
          export PATH=$PATH:$(go env GOPATH)/bin

          # Combine httpx results
          find . -name "httpx-results-*" -type d -exec cat {}/*.txt \; | grep '?' | sort -u > dynamic-alive.txt || true

          # Always include health check
          echo "https://1.bigdav.ir/test.php?test=KXSS" > kxss-urls-${{ matrix.chunk }}.txt

          if [[ -s "dynamic-alive.txt" ]] && [[ -s "combined-results/unfurl-params.txt" ]]; then
            # Read URLs and parameters
            mapfile -t urls < <(sort -u dynamic-alive.txt)
            mapfile -t params < <(sort -u combined-results/unfurl-params.txt)

            # Generate parameter combinations for this chunk
            TOTAL_COMBINATIONS=$((${#urls[@]} * ${#params[@]}))
            COMBINATIONS_PER_CHUNK=$((TOTAL_COMBINATIONS / 6 + 1))
            START_COMBINATION=$((((${{ matrix.chunk }} - 1) * COMBINATIONS_PER_CHUNK) + 1))
            END_COMBINATION=$((${{ matrix.chunk }} * COMBINATIONS_PER_CHUNK))

            combination_count=0
            for url in "${urls[@]}"; do
              for param in "${params[@]}"; do
                ((combination_count++))
                if [[ $combination_count -ge $START_COMBINATION ]] && [[ $combination_count -le $END_COMBINATION ]]; then
                  # Generate single parameter URL
                  if [[ "$url" == *"?${param}="* ]]; then
                    echo "$url" | sed "s/[?&]${param}=[^&]*/\0KXSS/" >> kxss-urls-${{ matrix.chunk }}.txt
                  elif [[ "$url" == *\?* ]]; then
                    echo "${url}&${param}=KXSS" >> kxss-urls-${{ matrix.chunk }}.txt
                  else
                    echo "${url}?${param}=KXSS" >> kxss-urls-${{ matrix.chunk }}.txt
                  fi
                fi
              done
            done
          fi

          # Remove duplicates and run kxss
          sort -u kxss-urls-${{ matrix.chunk }}.txt > kxss-urls-final-${{ matrix.chunk }}.txt

          if [[ -s "kxss-urls-final-${{ matrix.chunk }}.txt" ]]; then
            timeout 300 kxss < kxss-urls-final-${{ matrix.chunk }}.txt > kxss-results-${{ matrix.chunk }}/kxss.txt || true
          else
            touch kxss-results-${{ matrix.chunk }}/kxss.txt
          fi

      - name: Upload kxss results
        uses: actions/upload-artifact@v4
        with:
          name: kxss-results-${{ matrix.chunk }}
          path: kxss-results-${{ matrix.chunk }}/

  # Job 4: Final summary
  final-summary:
    needs: [httpx-scan, x8-scan, kxss-scan]
    runs-on: ubuntu-latest
    steps:
      - name: Download all results
        uses: actions/download-artifact@v4
        with:
          pattern: "*"
          merge-multiple: true

      - name: Generate final summary
        run: |
          # Set domain variable
          DOMAIN="${{ inputs.domain }}"

          # Combine all results
          find . -name "httpx-results-*" -type d -exec cat {}/*.txt \; > httpx.txt || true
          find . -name "httpx-results-*" -type d -exec grep '?' {}/*.txt \; > dynamic-httpx.txt || true
          find . -name "x8-results-*" -type d -exec cat {}/*.txt \; > x8-brute.txt || true
          find . -name "kxss-results-*" -type d -exec cat {}/*.txt \; > kxss-out.txt || true

          # Parse kxss output
          awk '
          /^URL: .* Param: .* Unfiltered: / {
            url_start = index($0, "URL: ") + 5
            param_pos = index($0, " Param: ")
            url = substr($0, url_start, param_pos - url_start)

            param_start = param_pos + 8
            unfilt_pos = index($0, " Unfiltered: ")
            param = substr($0, param_start, unfilt_pos - param_start)

            unfilt_start = unfilt_pos + 13
            unfiltered = substr($0, unfilt_start)

            if (unfiltered != "[]" && unfiltered != "" && url != "" && param != "") {
              print url " | " param " | Unfiltered: " unfiltered
            }
          }
          ' kxss-out.txt > kxss-reflected-pairs.txt

          # Count function
          count_or_zero(){
            [[ -f "$1" ]] && wc -l < "$1" || echo 0
          }

          # Generate summary
          WAYBACK_COUNT=$(count_or_zero passive-wayback/waybackurls.txt)
          GAU_COUNT=$(count_or_zero passive-gau/gau.txt)
          ALLURLS_COUNT=$(count_or_zero combined-results/all-urls.txt)
          STATIC_COUNT=$(grep -iv "?" combined-results/all-urls.txt 2>/dev/null | sort -u | wc -l || echo 0)
          DYNAMIC_COUNT=$(count_or_zero dynamic-httpx.txt)
          HTTPX_COUNT=$(count_or_zero httpx.txt)
          UNFURLPARAMS_COUNT=$(count_or_zero combined-results/unfurl-params.txt)
          X8_COUNT=$(count_or_zero x8-brute.txt)
          KXSS_COUNT=$(count_or_zero kxss-out.txt)

          echo "============ Recon Summary for $DOMAIN ============"
          printf "%-22s: %d
" "waybackurls" "$WAYBACK_COUNT"
          printf "%-22s: %d
" "gau" "$GAU_COUNT"
          printf "%-22s: %d
" "All unique URLs" "$ALLURLS_COUNT"
          printf "%-22s: %d
" "Static URLs" "$STATIC_COUNT"
          printf "%-22s: %d
" "Dynamic URLs" "$DYNAMIC_COUNT"
          printf "%-22s: %d
" "Unique URL params" "$UNFURLPARAMS_COUNT"
          printf "%-22s: %d
" "httpx (alive URLs)" "$HTTPX_COUNT"
          printf "%-22s: %d
" "x8 reflections lines" "$X8_COUNT"
          printf "%-22s: %d
" "kxss scan lines" "$KXSS_COUNT"
          if [[ -n "${{ inputs.headers }}" ]]; then
            printf "%-22s: %s
" "Headers used" "${{ inputs.headers }}"
          fi
          echo "=================================================="

          # Show reflected pairs
          if [[ -s "kxss-reflected-pairs.txt" ]]; then
            echo "[*] First 5 reflected pairs:"
            head -5 "kxss-reflected-pairs.txt"
          else
            echo "[!] No reflected pairs found."
          fi

          # Health check
          if grep -q "1.bigdav.ir" "kxss-reflected-pairs.txt"; then
            echo "[✓] Health check passed."
          else
            echo "[✗] Health check failed."
          fi

          # Save final results for upload
          mkdir -p final-results
          cp httpx.txt final-results/ || true
          cp dynamic-httpx.txt final-results/ || true
          cp x8-brute.txt final-results/ || true
          cp kxss-out.txt final-results/ || true
          cp kxss-reflected-pairs.txt final-results/ || true

          # Save summary
          echo "============ Recon Summary for $DOMAIN ============" > final-results/FINAL_SUMMARY.txt
          printf "%-22s: %d
" "waybackurls" "$WAYBACK_COUNT" >> final-results/FINAL_SUMMARY.txt
          printf "%-22s: %d
" "gau" "$GAU_COUNT" >> final-results/FINAL_SUMMARY.txt
          printf "%-22s: %d
" "All unique URLs" "$ALLURLS_COUNT" >> final-results/FINAL_SUMMARY.txt
          printf "%-22s: %d
" "Static URLs" "$STATIC_COUNT" >> final-results/FINAL_SUMMARY.txt
          printf "%-22s: %d
" "Dynamic URLs" "$DYNAMIC_COUNT" >> final-results/FINAL_SUMMARY.txt
          printf "%-22s: %d
" "Unique URL params" "$UNFURLPARAMS_COUNT" >> final-results/FINAL_SUMMARY.txt
          printf "%-22s: %d
" "httpx (alive URLs)" "$HTTPX_COUNT" >> final-results/FINAL_SUMMARY.txt
          printf "%-22s: %d
" "x8 reflections lines" "$X8_COUNT" >> final-results/FINAL_SUMMARY.txt
          printf "%-22s: %d
" "kxss scan lines" "$KXSS_COUNT" >> final-results/FINAL_SUMMARY.txt
          if [[ -n "${{ inputs.headers }}" ]]; then
            printf "%-22s: %s
" "Headers used" "${{ inputs.headers }}" >> final-results/FINAL_SUMMARY.txt
          fi
          echo "==================================================" >> final-results/FINAL_SUMMARY.txt

      - name: Upload final results
        uses: actions/upload-artifact@v4
        with:
          name: FINAL-RESULTS-${{ inputs.domain }}
          path: final-results/
