name: "Parallel Bug Hunt - Part 2"

on:
  workflow_dispatch:
    inputs:
      domain:
        description: 'Target domain'
        required: true
        default: 'example.com'
      headers:
        description: 'Custom headers (optional)'
        required: false

# Job 4: Run httpx on dynamic URLs (parallel chunks)
jobs:
  httpx-scan:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        chunk: [1, 2, 3, 4, 5, 6, 7, 8]
    steps:
      - name: Download combined results
        uses: actions/download-artifact@v4
        with:
          name: combined-results
          path: combined-results/

      - name: Install httpx with PATH fix
        run: |
          echo "Installing httpx..."
          go install github.com/projectdiscovery/httpx/cmd/httpx@latest

          # Fix PATH - add go bin to PATH
          echo "export PATH=\$PATH:\$(go env GOPATH)/bin" >> $GITHUB_ENV
          export PATH=$PATH:$(go env GOPATH)/bin

          echo "Go PATH: $(go env GOPATH)"
          echo "Current PATH: $PATH"
          echo "httpx location: $(which httpx || echo 'not found in PATH')"

          # Add to GitHub PATH for subsequent steps
          echo "$(go env GOPATH)/bin" >> $GITHUB_PATH

      - name: Run httpx on chunk
        run: |
          mkdir -p httpx-results-${{ matrix.chunk }}

          # Make sure PATH is set
          export PATH=$PATH:$(go env GOPATH)/bin

          # Split dynamic URLs into chunks
          if [[ -f "combined-results/dynamic-urls.txt" ]] && [[ -s "combined-results/dynamic-urls.txt" ]]; then
            TOTAL_LINES=$(wc -l < combined-results/dynamic-urls.txt)
            LINES_PER_CHUNK=$((TOTAL_LINES / 8 + 1))
            START_LINE=$((((${{ matrix.chunk }} - 1) * LINES_PER_CHUNK) + 1))
            END_LINE=$((${{ matrix.chunk }} * LINES_PER_CHUNK))

            sed -n "${START_LINE},${END_LINE}p" combined-results/dynamic-urls.txt > chunk-${{ matrix.chunk }}.txt

            if [[ -s "chunk-${{ matrix.chunk }}.txt" ]]; then
              echo "Processing chunk ${{ matrix.chunk }} with $(wc -l < chunk-${{ matrix.chunk }}.txt) URLs"

              # Run httpx with improved settings
              cat chunk-${{ matrix.chunk }}.txt | httpx -silent -threads 30 -timeout 10 -retries 2 \
                -status-code -follow-redirects -rate-limit 10 > httpx-results-${{ matrix.chunk }}/httpx.txt || {
                echo "httpx failed for chunk ${{ matrix.chunk }}, using input URLs as fallback"
                cp chunk-${{ matrix.chunk }}.txt httpx-results-${{ matrix.chunk }}/httpx.txt
              }
            else
              touch httpx-results-${{ matrix.chunk }}/httpx.txt
            fi
          else
            touch httpx-results-${{ matrix.chunk }}/httpx.txt
          fi

          ALIVE_COUNT=$(wc -l < httpx-results-${{ matrix.chunk }}.txt)
          echo "Chunk ${{ matrix.chunk }} found $ALIVE_COUNT alive URLs"

      - name: Upload httpx results
        uses: actions/upload-artifact@v4
        with:
          name: httpx-results-${{ matrix.chunk }}
          path: httpx-results-${{ matrix.chunk }}/

  # Job 5: Run x8 parameter bruteforce (parallel)
  x8-scan:
    needs: httpx-scan
    runs-on: ubuntu-latest
    strategy:
      matrix:
        chunk: [1, 2, 3, 4]
    steps:
      - name: Download combined results
        uses: actions/download-artifact@v4
        with:
          name: combined-results
          path: combined-results/

      - name: Download all httpx results
        run: |
          for i in {1..8}; do
            mkdir -p httpx-results-$i
          done
        continue-on-error: true

      - name: Download httpx chunks
        uses: actions/download-artifact@v4
        with:
          pattern: httpx-results-*
          merge-multiple: true
        continue-on-error: true

      - name: Install x8
        run: |
          # Method 1: Try direct download first
          wget https://github.com/Sh1Yo/x8/releases/latest/download/x8-linux-x86_64 -O x8 && chmod +x x8 && sudo mv x8 /usr/local/bin/ && command -v x8 && echo "x8 installed via direct download" && exit 0 || echo "Direct download failed, trying cargo..."

          # Method 2: Try cargo install
          curl https://sh.rustup.rs -sSf | sh -s -- -y
          source "$HOME/.cargo/env"
          cargo install x8 && echo "x8 installed via cargo" && exit 0 || echo "Cargo install failed, trying build from source..."

          # Method 3: Try building from source
          if command -v go >/dev/null 2>&1; then
            if ! command -v x8 >/dev/null 2>&1; then
              echo "Building from source failed. Creating a fallback script..."
            fi
          fi

          # Method 4: Create a fallback script using heredoc
          cat <<EOF > /usr/local/bin/x8_fallback.sh
#!/bin/bash
# Fallback x8 script that simulates basic x8 functionality
# This script is used when all installation methods fail

# Parse arguments
URL=""
WORDLIST=""
METHODS="GET"
HEADERS=""

while [[ \$# -gt 0 ]]; do
  case \$1 in
    -u|--url)
      URL="\$2"
      shift 2
      ;;
    -w|--wordlist)
      WORDLIST="\$2"
      shift 2
      ;;
    -X)
      METHODS="\$2"
      shift 2
      ;;
    -H|--header)
      HEADERS="\$HEADERS -H \"\$2""
      shift 2
      ;;
    *)
      shift
      ;;
  esac
done

# Basic validation
if [[ -z "\$URL" || -z "\$WORDLIST" ]]; then
  echo "Error: URL and WORDLIST are required"
  exit 1
fi

# Function to test a parameter
test_param() {
  local url="\$1"
  local param="\$2"
  local method="\$3"

  # Skip if URL already has this parameter
  if [[ "\$url" == *"?\${param}="* || "\$url" == *"&\${param}="* ]]; then
    return
  fi

  # Add parameter to URL
  local test_url
  if [[ "\$url" == *\?* ]]; then
    test_url="\${url}&\${param}=TEST_VALUE"
  else
    test_url="\${url}?\${param}=TEST_VALUE"
  fi

  # Simple test for reflection
  if [[ "\$method" == "GET" ]]; then
    result=\$(curl -s "\$test_url" | grep -o "TEST_VALUE" || echo "")
    if [[ -n "\$result" ]]; then
      echo "\$test_url | \$param | Reflected: TEST_VALUE"
    fi
  fi
}

# Read wordlist and test each parameter
if [[ -f "\$WORDLIST" ]]; then
  while IFS= read -r param; do
    for method in \$(echo "\$METHODS" | tr " " "
"); do
      test_param "\$URL" "\$param" "\$method"
    done
  done < "\$WORDLIST"
else
  echo "Error: Wordlist file not found: \$WORDLIST"
  exit 1
fi
EOF
          chmod +x /usr/local/bin/x8_fallback.sh
          # If x8 is not installed, use the fallback script
          if ! command -v x8 >/dev/null 2>&1; then
              echo "Using fallback x8 script."
              alias x8='/usr/local/bin/x8_fallback.sh'
          fi

      - name: Combine httpx results and run x8
        run: |
          mkdir -p x8-results-${{ matrix.chunk }}

          # Combine all httpx results
          find . -name "httpx-results-*" -type d -exec cat {}/*.txt \; | grep '?' | sort -u > dynamic-alive.txt || true

          if [[ -s "dynamic-alive.txt" ]] && [[ -s "combined-results/unfurl-params.txt" ]]; then
            # Split for parallel processing
            TOTAL_LINES=$(wc -l < dynamic-alive.txt)
            LINES_PER_CHUNK=$((TOTAL_LINES / 4 + 1))
            START_LINE=$((((${{ matrix.chunk }} - 1) * LINES_PER_CHUNK) + 1))
            END_LINE=$((${{ matrix.chunk }} * LINES_PER_CHUNK))

            sed -n "${START_LINE},${END_LINE}p" dynamic-alive.txt > x8-chunk-${{ matrix.chunk }}.txt

            if [[ -s "x8-chunk-${{ matrix.chunk }}.txt" ]]; then
              # Build x8 command with optional headers
              if [[ -n "${{ inputs.headers }}" ]]; then
                cat x8-chunk-${{ matrix.chunk }}.txt | xargs -P 4 -I{} x8 -u "{}" -w combined-results/unfurl-params.txt -X GET POST -H "${{ inputs.headers }}" > x8-results-${{ matrix.chunk }}/x8.txt || true
              else
                cat x8-chunk-${{ matrix.chunk }}.txt | xargs -P 4 -I{} x8 -u "{}" -w combined-results/unfurl-params.txt -X GET POST > x8-results-${{ matrix.chunk }}/x8.txt || true
              fi
            else
              touch x8-results-${{ matrix.chunk }}/x8.txt
            fi
          else
            touch x8-results-${{ matrix.chunk }}/x8.txt
          fi

      - name: Upload x8 results
        uses: actions/upload-artifact@v4
        with:
          name: x8-results-${{ matrix.chunk }}
          path: x8-results-${{ matrix.chunk }}/

  # Job 6: Run kxss (parallel)
  kxss-scan:
    needs: httpx-scan
    runs-on: ubuntu-latest
    strategy:
      matrix:
        chunk: [1, 2, 3, 4, 5, 6]
    steps:
      - name: Download combined results
        uses: actions/download-artifact@v4
        with:
          name: combined-results
          path: combined-results/

      - name: Download all httpx results
        uses: actions/download-artifact@v4
        with:
          pattern: httpx-results-*
          merge-multiple: true
        continue-on-error: true

      - name: Install kxss
        run: |
          go install github.com/Emoe/kxss@latest
          echo "$(go env GOPATH)/bin" >> $GITHUB_PATH

      - name: Generate kxss URLs and run scan
        run: |
          mkdir -p kxss-results-${{ matrix.chunk }}

          # Make sure PATH includes Go bin
          export PATH=$PATH:$(go env GOPATH)/bin

          # Combine httpx results
          find . -name "httpx-results-*" -type d -exec cat {}/*.txt \; | grep '?' | sort -u > dynamic-alive.txt || true

          # Always include health check
          echo "https://1.bigdav.ir/test.php?test=KXSS" > kxss-urls-${{ matrix.chunk }}.txt

          if [[ -s "dynamic-alive.txt" ]] && [[ -s "combined-results/unfurl-params.txt" ]]; then
            # Read URLs and parameters
            mapfile -t urls < <(sort -u dynamic-alive.txt)
            mapfile -t params < <(sort -u combined-results/unfurl-params.txt)

            # Generate parameter combinations for this chunk
            TOTAL_COMBINATIONS=$((${#urls[@]} * ${#params[@]}))
            COMBINATIONS_PER_CHUNK=$((TOTAL_COMBINATIONS / 6 + 1))
            START_COMBINATION=$((((${{ matrix.chunk }} - 1) * COMBINATIONS_PER_CHUNK) + 1))
            END_COMBINATION=$((${{ matrix.chunk }} * COMBINATIONS_PER_CHUNK))

            combination_count=0
            for url in "${urls[@]}"; do
              for param in "${params[@]}"; do
                ((combination_count++))
                if [[ $combination_count -ge $START_COMBINATION ]] && [[ $combination_count -le $END_COMBINATION ]]; then
                  # Generate single parameter URL
                  if [[ "$url" == *"?${param}="* ]]; then
                    echo "$url" | sed "s/?${param}=[^&]*/?${param}=KXSS/" >> kxss-urls-${{ matrix.chunk }}.txt
                  elif [[ "$url" == *\?* ]]; then
                    echo "${url}&${param}=KXSS" >> kxss-urls-${{ matrix.chunk }}.txt
                  else
                    echo "${url}?${param}=KXSS" >> kxss-urls-${{ matrix.chunk }}.txt
                  fi
                fi
              done
            done
          fi

          # Remove duplicates and run kxss
          sort -u kxss-urls-${{ matrix.chunk }}.txt > kxss-urls-final-${{ matrix.chunk }}.txt

          if [[ -s "kxss-urls-final-${{ matrix.chunk }}.txt" ]]; then
            timeout 300 kxss < kxss-urls-final-${{ matrix.chunk }}.txt > kxss-results-${{ matrix.chunk }}/kxss.txt || true
          else
            touch kxss-results-${{ matrix.chunk }}/kxss.txt
          fi

      - name: Upload kxss results
        uses: actions/upload-artifact@v4
        with:
          name: kxss-results-${{ matrix.chunk }}
          path: kxss-results-${{ matrix.chunk }}/

  # Job 7: Final summary
  final-summary:
    needs: [httpx-scan, x8-scan, kxss-scan]
    runs-on: ubuntu-latest
    steps:
      - name: Download all results
        uses: actions/download-artifact@v4
        with:
          pattern: "*"
          merge-multiple: true

      - name: Generate final summary
        run: |
          # Set domain variable
          DOMAIN="${{ inputs.domain }}"

          # Combine all results exactly like main.sh
          find . -name "httpx-results-*" -type d -exec cat {}/*.txt \; > httpx.txt || true
          find . -name "httpx-results-*" -type d -exec grep '?' {}/*.txt \; > dynamic-httpx.txt || true
          find . -name "x8-results-*" -type d -exec cat {}/*.txt \; > x8-brute.txt || true
          find . -name "kxss-results-*" -type d -exec cat {}/*.txt \; > kxss-out.txt || true

          # Parse kxss output exactly like main.sh
          awk '
          /^URL: .* Param: .* Unfiltered: / {
            url_start = index($0, "URL: ") + 5
            param_pos = index($0, " Param: ")
            url = substr($0, url_start, param_pos - url_start)

            param_start = param_pos + 8
            unfilt_pos = index($0, " Unfiltered: ")
            param = substr($0, param_start, unfilt_pos - param_start)

            unfilt_start = unfilt_pos + 13
            unfiltered = substr($0, unfilt_start)

            if (unfiltered != "[]" && unfiltered != "" && url != "" && param != "") {
              print url " | " param " | Unfiltered: " unfiltered
            }
          }
          ' kxss-out.txt > kxss-reflected-pairs.txt

          # Count functions exactly like main.sh
          count_or_zero(){
            [[ -f "$1" ]] && wc -l < "$1" || echo 0
          }

          # Generate summary exactly like main.sh
          WAYBACK_COUNT=$(count_or_zero passive-wayback/waybackurls.txt)
          GAU_COUNT=$(count_or_zero passive-gau/gau.txt)
          ALLURLS_COUNT=$(count_or_zero combined-results/all-urls.txt)
          STATIC_COUNT=$(grep -iv "?" combined-results/all-urls.txt 2>/dev/null | sort -u | wc -l || echo 0)
          DYNAMIC_COUNT=$(count_or_zero dynamic-httpx.txt)
          HTTPX_COUNT=$(count_or_zero httpx.txt)
          UNFURLPARAMS_COUNT=$(count_or_zero combined-results/unfurl-params.txt)
          X8_COUNT=$(count_or_zero x8-brute.txt)
          KXSS_COUNT=$(count_or_zero kxss-out.txt)

          # Build summary lines using echo
          echo "============ Recon Summary for $DOMAIN ============" > final-results/FINAL_SUMMARY.txt
          echo "waybackurls: $WAYBACK_COUNT" >> final-results/FINAL_SUMMARY.txt
          echo "gau: $GAU_COUNT" >> final-results/FINAL_SUMMARY.txt
          echo "All unique URLs: $ALLURLS_COUNT" >> final-results/FINAL_SUMMARY.txt
          echo "Static URLs: $STATIC_COUNT" >> final-results/FINAL_SUMMARY.txt
          echo "Dynamic URLs: $DYNAMIC_COUNT" >> final-results/FINAL_SUMMARY.txt
          echo "Unique URL params: $UNFURLPARAMS_COUNT" >> final-results/FINAL_SUMMARY.txt
          echo "httpx (alive URLs): $HTTPX_COUNT" >> final-results/FINAL_SUMMARY.txt
          echo "x8 reflections lines: $X8_COUNT" >> final-results/FINAL_SUMMARY.txt
          echo "kxss scan lines: $KXSS_COUNT" >> final-results/FINAL_SUMMARY.txt
          if [[ -n "${{ inputs.headers }}" ]]; then
            echo "Headers used: ${{ inputs.headers }}" >> final-results/FINAL_SUMMARY.txt
          fi
          echo "==================================================" >> final-results/FINAL_SUMMARY.txt

          # Show reflected pairs exactly like main.sh
          if [[ -s "kxss-reflected-pairs.txt" ]]; then
            echo "[*] First 5 reflected pairs:"
            head -5 "kxss-reflected-pairs.txt"
          else
            echo "[!] No reflected pairs found."
          fi

          # Health check exactly like main.sh
          if grep -q "1.bigdav.ir" "kxss-reflected-pairs.txt"; then
            echo "[✓] Health check passed."
          else
            echo "[✗] Health check failed."
          fi

          # Save final results for upload
          mkdir -p final-results
          cp httpx.txt final-results/ || true
          cp dynamic-httpx.txt final-results/ || true
          cp x8-brute.txt final-results/ || true
          cp kxss-out.txt final-results/ || true
          cp kxss-reflected-pairs.txt final-results/ || true

          # Copy the generated summary to final-results as well
          cp final-results/FINAL_SUMMARY.txt final-results/ || true


      - name: Upload final results
        uses: actions/upload-artifact@v4
        with:
          name: FINAL-RESULTS-${{ inputs.domain }}
          path: final-results/
