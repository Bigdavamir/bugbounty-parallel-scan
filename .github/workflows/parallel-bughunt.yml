name: XSS Scanner

on:
  workflow_dispatch:
    inputs:
      domain:
        description: 'Target domain (e.g., example.com)'
        required: true
        type: string
      headers:
        description: 'Optional HTTP headers (e.g., "Cookie: session=abc123")'
        required: false
        type: string
        default: ''

jobs:
  # Job 1: URL Collection
  url-collection:
    runs-on: ubuntu-latest
    steps:
      - name: Install dependencies
        run: |
          # Install Go tools
          go install github.com/tomnomnom/waybackurls@latest
          go install github.com/lc/gau/v2/cmd/gau@latest
          go install github.com/tomnomnom/unfurl@latest
          go install github.com/tomnomnom/anew@latest
          
          # Add Go bin to PATH
          echo "$HOME/go/bin" >> $GITHUB_PATH

      - name: Collect URLs
        run: |
          DOMAIN="${{ inputs.domain }}"
          
          # Create results directory
          mkdir -p combined-results
          
          # Extensions to filter out
          EXTS='(json|js|css|jpg|jpeg|png|svg|gif|exe|mp4|flv|pdf|doc|webm|wmv|webp|mov|mp3|avi|zip)($|\?)'
          
          echo "Starting URL collection for $DOMAIN..."
          
          # Collect URLs from different sources
          echo "https://${DOMAIN}/" > all-raw-urls.txt
          
          # Waybackurls
          echo "$DOMAIN" | waybackurls | tee waybackurls.txt >> all-raw-urls.txt
          
          # GAU with subdomains
          gau "$DOMAIN" --threads 5 --subs | tee gau.txt >> all-raw-urls.txt
          
          # Clean and deduplicate
          sort -u all-raw-urls.txt > all-clean-urls.txt
          
          # Filter out unwanted extensions and save
          grep -iEv "\.${EXTS}" all-clean-urls.txt | awk 'NF' | anew "${DOMAIN}.passive"
          
          # Split into static and dynamic URLs
          grep -v '?' "${DOMAIN}.passive" | sort -u > static-urls.txt
          grep '?' "${DOMAIN}.passive" | sort -u > dynamic-urls.txt
          
          # Extract parameters
          unfurl --unique keys < "${DOMAIN}.passive" | sort -u > params.txt
          
          # Copy to combined results
          cp "${DOMAIN}.passive" combined-results/all-urls.txt
          cp params.txt combined-results/unfurl-params.txt
          cp static-urls.txt combined-results/
          cp dynamic-urls.txt combined-results/
          
          # Summary
          echo "URL Collection Summary:"
          echo "Total URLs: $(wc -l < all-clean-urls.txt)"
          echo "Clean URLs: $(wc -l < "${DOMAIN}.passive")"
          echo "Static URLs: $(wc -l < static-urls.txt)"
          echo "Dynamic URLs: $(wc -l < dynamic-urls.txt)"
          echo "Parameters: $(wc -l < params.txt)"

      - name: Upload URL collection results
        uses: actions/upload-artifact@v4
        with:
          name: url-collection
          path: combined-results/

  # Job 2: httpx validation
  httpx-scan:
    needs: url-collection
    runs-on: ubuntu-latest
    strategy:
      matrix:
        chunk: [1, 2, 3, 4]
    steps:
      - name: Download URL collection results
        uses: actions/download-artifact@v4
        with:
          name: url-collection
          path: combined-results/

      - name: Install httpx
        run: |
          go install -v github.com/projectdiscovery/httpx/cmd/httpx@latest
          echo "$HOME/go/bin" >> $GITHUB_PATH

      - name: Run httpx on chunk
        run: |
          mkdir -p httpx-results-${{ matrix.chunk }}
          
          if [[ -s "combined-results/dynamic-urls.txt" ]]; then
            # Split dynamic URLs into chunks
            TOTAL_LINES=$(wc -l < combined-results/dynamic-urls.txt)
            LINES_PER_CHUNK=$((TOTAL_LINES / 4 + 1))
            START_LINE=$((((${{ matrix.chunk }} - 1) * LINES_PER_CHUNK) + 1))
            END_LINE=$((${{ matrix.chunk }} * LINES_PER_CHUNK))
            
            sed -n "${START_LINE},${END_LINE}p" combined-results/dynamic-urls.txt > chunk-${{ matrix.chunk }}.txt
            
            if [[ -s "chunk-${{ matrix.chunk }}.txt" ]]; then
              echo "Processing chunk ${{ matrix.chunk }} with $(wc -l < chunk-${{ matrix.chunk }}.txt) URLs"
              httpx -silent -threads 100 -timeout 3 -retries 2 < chunk-${{ matrix.chunk }}.txt > httpx-results-${{ matrix.chunk }}/alive.txt
              echo "Chunk ${{ matrix.chunk }}: Found $(wc -l < httpx-results-${{ matrix.chunk }}/alive.txt) live URLs"
            else
              touch httpx-results-${{ matrix.chunk }}/alive.txt
              echo "Chunk ${{ matrix.chunk }}: No URLs to process"
            fi
          else
            touch httpx-results-${{ matrix.chunk }}/alive.txt
            echo "Chunk ${{ matrix.chunk }}: No dynamic URLs found"
          fi

      - name: Upload httpx results
        uses: actions/upload-artifact@v4
        with:
          name: httpx-results-${{ matrix.chunk }}
          path: httpx-results-${{ matrix.chunk }}/

  # Job 3: x8 parameter discovery
  x8-scan:
    needs: httpx-scan
    runs-on: ubuntu-latest
    strategy:
      matrix:
        chunk: [1, 2, 3, 4]
    steps:
      - name: Download URL collection results
        uses: actions/download-artifact@v4
        with:
          name: url-collection
          path: combined-results/

      - name: Download httpx results
        uses: actions/download-artifact@v4
        with:
          pattern: httpx-results-*
          merge-multiple: true

      - name: Install x8
        run: |
          echo "Installing x8..."
          
          # Method 1: Try direct download with latest
          if wget -q https://github.com/Sh1Yo/x8/releases/latest/download/x8-linux-x86_64 -O x8; then
            chmod +x x8
            sudo mv x8 /usr/local/bin/
            echo "x8 installed successfully via direct download"
          else
            echo "Direct download failed, trying alternative methods..."
            
            # Method 2: Try different release versions
            VERSIONS=("v4.1.0" "v4.0.0" "v3.1.0" "v3.0.0")
            INSTALLED=false
            
            for version in "${VERSIONS[@]}"; do
              echo "Trying version $version..."
              if wget -q "https://github.com/Sh1Yo/x8/releases/download/${version}/x8-linux-x86_64" -O x8; then
                chmod +x x8
                sudo mv x8 /usr/local/bin/
                echo "x8 installed successfully with version $version"
                INSTALLED=true
                break
              fi
            done
            
            # Method 3: Build from source if all else fails
            if [ "$INSTALLED" = false ]; then
              echo "All binary downloads failed, building from source..."
              sudo apt update
              sudo apt install -y build-essential
              
              # Install Rust
              curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh -s -- -y
              source ~/.cargo/env
              export PATH="$HOME/.cargo/bin:$PATH"
              
              # Clone and build x8
              git clone https://github.com/Sh1Yo/x8.git
              cd x8
              timeout 600 cargo build --release || {
                echo "Cargo build timed out or failed"
                cd ..
                INSTALLED=false
              }
              
              if [[ -f "target/release/x8" ]]; then
                sudo cp target/release/x8 /usr/local/bin/
                cd ..
                rm -rf x8
                echo "x8 built and installed from source"
                INSTALLED=true
              else
                cd ..
                rm -rf x8
                INSTALLED=false
              fi
            fi
            
            # Method 4: Create dummy if everything fails
            if [ "$INSTALLED" = false ]; then
              echo "x8 installation failed, creating dummy script"
              sudo tee /usr/local/bin/x8 > /dev/null << 'EOF'
          #!/bin/bash
          echo "x8 not available, skipping parameter bruteforce"
          EOF
              sudo chmod +x /usr/local/bin/x8
            fi
          fi
          
          # Verify installation
          if command -v x8 >/dev/null 2>&1; then
            echo "x8 installation verified: $(x8 --version 2>/dev/null || echo 'binary exists')"
          else
            echo "x8 installation verification failed"
          fi

      - name: Combine httpx results and run x8
        run: |
          mkdir -p x8-results-${{ matrix.chunk }}

          # Combine all httpx results
          find . -name "httpx-results-*" -type d -exec cat {}/*.txt \; | grep '?' | sort -u > dynamic-alive.txt || true

          if [[ -s "dynamic-alive.txt" ]] && [[ -s "combined-results/unfurl-params.txt" ]]; then
            # Split for parallel processing
            TOTAL_LINES=$(wc -l < dynamic-alive.txt)
            LINES_PER_CHUNK=$((TOTAL_LINES / 4 + 1))
            START_LINE=$((((${{ matrix.chunk }} - 1) * LINES_PER_CHUNK) + 1))
            END_LINE=$((${{ matrix.chunk }} * LINES_PER_CHUNK))

            sed -n "${START_LINE},${END_LINE}p" dynamic-alive.txt > x8-chunk-${{ matrix.chunk }}.txt

            if [[ -s "x8-chunk-${{ matrix.chunk }}.txt" ]] && command -v x8 >/dev/null 2>&1; then
              echo "Running x8 on chunk ${{ matrix.chunk }} with $(wc -l < x8-chunk-${{ matrix.chunk }}.txt) URLs"
              
              # Test if x8 is working
              if x8 --version >/dev/null 2>&1 || x8 --help >/dev/null 2>&1; then
                # Build x8 command with optional headers and error handling
                if [[ -n "${{ inputs.headers }}" ]]; then
                  cat x8-chunk-${{ matrix.chunk }}.txt | timeout 300 xargs -P 4 -I{} x8 -u "{}" -w combined-results/unfurl-params.txt -X GET POST -H "${{ inputs.headers }}" > x8-results-${{ matrix.chunk }}/x8.txt 2>/dev/null || {
                    echo "x8 failed or timed out for chunk ${{ matrix.chunk }}"
                    touch x8-results-${{ matrix.chunk }}/x8.txt
                  }
                else
                  cat x8-chunk-${{ matrix.chunk }}.txt | timeout 300 xargs -P 4 -I{} x8 -u "{}" -w combined-results/unfurl-params.txt -X GET POST > x8-results-${{ matrix.chunk }}/x8.txt 2>/dev/null || {
                    echo "x8 failed or timed out for chunk ${{ matrix.chunk }}"
                    touch x8-results-${{ matrix.chunk }}/x8.txt
                  }
                fi
              else
                echo "x8 dummy detected, skipping actual scan"
                echo "# x8 scan skipped - installation failed" > x8-results-${{ matrix.chunk }}/x8.txt
              fi
            else
              echo "x8 not available or no URLs to process for chunk ${{ matrix.chunk }}"
              touch x8-results-${{ matrix.chunk }}/x8.txt
            fi
          else
            echo "No dynamic URLs or parameters found for x8 chunk ${{ matrix.chunk }}"
            touch x8-results-${{ matrix.chunk }}/x8.txt
          fi
          
          echo "x8 chunk ${{ matrix.chunk }} completed with $(wc -l < x8-results-${{ matrix.chunk }}/x8.txt) results"

      - name: Upload x8 results
        uses: actions/upload-artifact@v4
        with:
          name: x8-results-${{ matrix.chunk }}
          path: x8-results-${{ matrix.chunk }}/

  # Job 4: kxss scanning
  kxss-scan:
    needs: httpx-scan
    runs-on: ubuntu-latest
    strategy:
      matrix:
        chunk: [1, 2, 3, 4]
    steps:
      - name: Download URL collection results
        uses: actions/download-artifact@v4
        with:
          name: url-collection
          path: combined-results/

      - name: Download httpx results
        uses: actions/download-artifact@v4
        with:
          pattern: httpx-results-*
          merge-multiple: true

      - name: Install kxss
        run: |
          go install github.com/Emoe/kxss@latest
          echo "$HOME/go/bin" >> $GITHUB_PATH

      - name: Generate kxss URLs and run scan
        run: |
          mkdir -p kxss-results-${{ matrix.chunk }}
          
          # Combine all live URLs
          find . -name "httpx-results-*" -type d -exec cat {}/*.txt \; | grep '?' | sort -u > dynamic-alive.txt || true
          
          if [[ -s "dynamic-alive.txt" ]] && [[ -s "combined-results/unfurl-params.txt" ]]; then
            # Read parameters and URLs into arrays
            mapfile -t params < <(sort -u combined-results/unfurl-params.txt)
            mapfile -t urls < <(sort -u dynamic-alive.txt)
            
            if [[ ${#params[@]} -gt 0 ]] && [[ ${#urls[@]} -gt 0 ]]; then
              echo "Generating kxss URLs for chunk ${{ matrix.chunk }}"
              echo "Parameters: ${#params[@]}, URLs: ${#urls[@]}"
              
              # Function to generate URL with single parameter
              gen_single_param_url() {
                local base="$1"
                local param="$2"
                if [[ "$base" == *"?${param}="* ]]; then
                  echo "$base" | sed "s/\([\?&]${param}=\)[^&]*/\1KXSS/"
                elif [[ "$base" == *\?* ]]; then
                  echo "${base}&${param}=KXSS"
                else
                  echo "${base}?${param}=KXSS"
                fi
              }
              
              # Generate URLs for this chunk
              > kxss-urls-${{ matrix.chunk }}.txt
              
              # Health check URL
              echo "https://1.bigdav.ir/test.php?test=KXSS" >> kxss-urls-${{ matrix.chunk }}.txt
              
              # Calculate chunk boundaries
              TOTAL_COMBINATIONS=$((${#urls[@]} * ${#params[@]}))
              COMBINATIONS_PER_CHUNK=$((TOTAL_COMBINATIONS / 4 + 1))
              START_INDEX=$((((${{ matrix.chunk }} - 1) * COMBINATIONS_PER_CHUNK)))
              END_INDEX=$((${{ matrix.chunk }} * COMBINATIONS_PER_CHUNK))
              
              current_index=0
              for u in "${urls[@]}"; do
                for p in "${params[@]}"; do
                  if [[ $current_index -ge $START_INDEX ]] && [[ $current_index -lt $END_INDEX ]]; then
                    gen_single_param_url "$u" "$p" >> kxss-urls-${{ matrix.chunk }}.txt
                  fi
                  ((current_index++))
                  if [[ $current_index -ge $END_INDEX ]]; then
                    break 2
                  fi
                done
              done
              
              # Remove duplicates
              sort -u kxss-urls-${{ matrix.chunk }}.txt > kxss-urls-${{ matrix.chunk }}-clean.txt
              mv kxss-urls-${{ matrix.chunk }}-clean.txt kxss-urls-${{ matrix.chunk }}.txt
              
              URL_COUNT=$(wc -l < kxss-urls-${{ matrix.chunk }}.txt)
              echo "Generated $URL_COUNT URLs for kxss chunk ${{ matrix.chunk }}"
              
              if [[ $URL_COUNT -gt 0 ]] && command -v kxss >/dev/null 2>&1; then
                echo "Running kxss on chunk ${{ matrix.chunk }} with $URL_COUNT URLs"
                
                # Run kxss with timeout
                timeout 600 kxss < kxss-urls-${{ matrix.chunk }}.txt > kxss-results-${{ matrix.chunk }}/kxss-raw.txt 2>/dev/null || {
                  echo "kxss failed or timed out for chunk ${{ matrix.chunk }}"
                  touch kxss-results-${{ matrix.chunk }}/kxss-raw.txt
                }
                
                # Parse kxss output
                awk '
                /^URL: .* Param: .* Unfiltered: / {
                  url_start = index($0, "URL: ") + 5
                  param_pos = index($0, " Param: ")
                  url = substr($0, url_start, param_pos - url_start)
                  
                  param_start = param_pos + 8
                  unfilt_pos = index($0, " Unfiltered: ")
                  param = substr($0, param_start, unfilt_pos - param_start)
                  
                  unfilt_start = unfilt_pos + 13
                  unfiltered = substr($0, unfilt_start)
                  
                  if (unfiltered != "[]" && unfiltered != "" && url != "" && param != "") {
                    print url " | " param " | Unfiltered: " unfiltered
                  }
                }
                ' kxss-results-${{ matrix.chunk }}/kxss-raw.txt > kxss-results-${{ matrix.chunk }}/kxss-reflections.txt
                
                REFLECTION_COUNT=$(wc -l < kxss-results-${{ matrix.chunk }}/kxss-reflections.txt)
                echo "kxss chunk ${{ matrix.chunk }} found $REFLECTION_COUNT reflections"
              else
                echo "kxss not available or no URLs for chunk ${{ matrix.chunk }}"
                touch kxss-results-${{ matrix.chunk }}/kxss-raw.txt
                touch kxss-results-${{ matrix.chunk }}/kxss-reflections.txt
              fi
            else
              echo "No parameters or URLs available for chunk ${{ matrix.chunk }}"
              touch kxss-results-${{ matrix.chunk }}/kxss-raw.txt
              touch kxss-results-${{ matrix.chunk }}/kxss-reflections.txt
            fi
          else
            echo "No live dynamic URLs or parameters found for chunk ${{ matrix.chunk }}"
            touch kxss-results-${{ matrix.chunk }}/kxss-raw.txt
            touch kxss-results-${{ matrix.chunk }}/kxss-reflections.txt
          fi

      - name: Upload kxss results
        uses: actions/upload-artifact@v4
        with:
          name: kxss-results-${{ matrix.chunk }}
          path: kxss-results-${{ matrix.chunk }}/

  # Job 5: Final summary
  final-summary:
    needs: [url-collection, httpx-scan, x8-scan, kxss-scan]
    runs-on: ubuntu-latest
    steps:
      - name: Download all results
        uses: actions/download-artifact@v4
        with:
          pattern: '*'
          merge-multiple: true

      - name: Generate comprehensive summary
        run: |
          echo "# XSS Scanner Results for ${{ inputs.domain }}" > FINAL_SUMMARY.txt
          echo "Generated on: $(date)" >> FINAL_SUMMARY.txt
          echo "" >> FINAL_SUMMARY.txt
          
          # URL Collection Summary
          echo "## URL Collection" >> FINAL_SUMMARY.txt
          echo "- All URLs: $(wc -l < all-urls.txt 2>/dev/null || echo 0)" >> FINAL_SUMMARY.txt
          echo "- Static URLs: $(wc -l < static-urls.txt 2>/dev/null || echo 0)" >> FINAL_SUMMARY.txt
          echo "- Dynamic URLs: $(wc -l < dynamic-urls.txt 2>/dev/null || echo 0)" >> FINAL_SUMMARY.txt
          echo "- Parameters: $(wc -l < unfurl-params.txt 2>/dev/null || echo 0)" >> FINAL_SUMMARY.txt
          echo "" >> FINAL_SUMMARY.txt
          
          # Combine all alive URLs
          find . -name "httpx-results-*" -type d -exec cat {}/*.txt \; | sort -u > all-alive-urls.txt 2>/dev/null || touch all-alive-urls.txt
          echo "## httpx Results" >> FINAL_SUMMARY.txt
          echo "- Total alive URLs: $(wc -l < all-alive-urls.txt)" >> FINAL_SUMMARY.txt
          echo "" >> FINAL_SUMMARY.txt
          
          # Combine all x8 results
          find . -name "x8-results-*" -type d -exec cat {}/x8.txt \; > all-x8-reflections.txt 2>/dev/null || touch all-x8-reflections.txt
          echo "## x8 Results" >> FINAL_SUMMARY.txt
          echo "- Total x8 output lines: $(wc -l < all-x8-reflections.txt)" >> FINAL_SUMMARY.txt
          if [[ -s all-x8-reflections.txt ]]; then
            REFLECTED_X8=$(grep -Ei 'reflects:|change reflect' all-x8-reflections.txt | wc -l)
            echo "- Potential reflections: $REFLECTED_X8" >> FINAL_SUMMARY.txt
          fi
          echo "" >> FINAL_SUMMARY.txt
          
          # Combine all kxss results
          find . -name "kxss-results-*" -type d -exec cat {}/kxss-reflections.txt \; > all-kxss-reflections.txt 2>/dev/null || touch all-kxss-reflections.txt
          echo "## kxss Results" >> FINAL_SUMMARY.txt
          KXSS_REFLECTIONS=$(wc -l < all-kxss-reflections.txt)
          echo "- Total reflections found: $KXSS_REFLECTIONS" >> FINAL_SUMMARY.txt
          echo "" >> FINAL_SUMMARY.txt
          
          if [[ $KXSS_REFLECTIONS -gt 0 ]]; then
            echo "### Top 10 kxss Reflections:" >> FINAL_SUMMARY.txt
            head -10 all-kxss-reflections.txt >> FINAL_SUMMARY.txt
            echo "" >> FINAL_SUMMARY.txt
          fi
          
          # Health check
          if grep -q "1.bigdav.ir" all-kxss-reflections.txt 2>/dev/null; then
            echo "✅ Health check: PASSED" >> FINAL_SUMMARY.txt
          else
            echo "❌ Health check: FAILED" >> FINAL_SUMMARY.txt
          fi
          echo "" >> FINAL_SUMMARY.txt
          
          # Headers info
          if [[ -n "${{ inputs.headers }}" ]]; then
            echo "Headers used: ${{ inputs.headers }}" >> FINAL_SUMMARY.txt
            echo "" >> FINAL_SUMMARY.txt
          fi
          
          echo "Scan completed successfully!" >> FINAL_SUMMARY.txt
          
          # Display summary
          cat FINAL_SUMMARY.txt

      - name: Upload final summary
        uses: actions/upload-artifact@v4
        with:
          name: final-summary
          path: |
            FINAL_SUMMARY.txt
            all-alive-urls.txt
            all-x8-reflections.txt
            all-kxss-reflections.txt
