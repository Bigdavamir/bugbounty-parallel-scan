name: XSS Scanner

on:
  workflow_dispatch:
    inputs:
      domain:
        description: 'Target domain (e.g., example.com)'
        required: true
        type: string
      headers:
        description: 'Optional HTTP headers (e.g., "Cookie: session=abc123")'
        required: false
        type: string
        default: ''

jobs:
  # Job 1: URL Collection
  url-collection:
    runs-on: ubuntu-latest
    steps:
      - name: Install dependencies
        run: |
          # Install Go tools
          go install github.com/tomnomnom/waybackurls@latest
          go install github.com/lc/gau/v2/cmd/gau@latest
          go install github.com/tomnomnom/unfurl@latest
          go install github.com/tomnomnom/anew@latest
          
          # Add Go bin to PATH
          echo "$HOME/go/bin" >> $GITHUB_PATH

      - name: Collect URLs
        run: |
          DOMAIN="${{ inputs.domain }}"
          
          # Create results directory
          mkdir -p combined-results
          
          # Extensions to filter out
          EXTS='(json|js|css|jpg|jpeg|png|svg|gif|exe|mp4|flv|pdf|doc|webm|wmv|webp|mov|mp3|avi|zip)($|\?)'
          
          echo "Starting URL collection for $DOMAIN..."
          
          # Collect URLs from different sources
          echo "https://${DOMAIN}/" > all-raw-urls.txt
          
          # Waybackurls with timeout
          echo "$DOMAIN" | timeout 120 waybackurls | tee waybackurls.txt >> all-raw-urls.txt || echo "waybackurls timeout/failed"
          
          # GAU with subdomains and timeout
          timeout 120 gau "$DOMAIN" --threads 5 --subs | tee gau.txt >> all-raw-urls.txt || echo "gau timeout/failed"
          
          # Clean and deduplicate
          sort -u all-raw-urls.txt > all-clean-urls.txt
          
          # Filter out unwanted extensions and save
          grep -iEv "\.${EXTS}" all-clean-urls.txt | awk 'NF' | anew "${DOMAIN}.passive" || cp all-clean-urls.txt "${DOMAIN}.passive"
          
          # Split into static and dynamic URLs
          grep -v '?' "${DOMAIN}.passive" | sort -u > static-urls.txt || touch static-urls.txt
          grep '?' "${DOMAIN}.passive" | sort -u > dynamic-urls.txt || touch dynamic-urls.txt
          
          # Extract parameters
          unfurl --unique keys < "${DOMAIN}.passive" | sort -u > params.txt || touch params.txt
          
          # Add some common parameters if none found
          if [[ ! -s params.txt ]]; then
            echo "No parameters found, adding common ones..."
            cat > params.txt << 'EOF'
          q
          query
          search
          id
          page
          url
          redirect
          callback
          jsonp
          return
          next
          EOF
          fi
          
          # Copy to combined results
          cp "${DOMAIN}.passive" combined-results/all-urls.txt
          cp params.txt combined-results/unfurl-params.txt
          cp static-urls.txt combined-results/
          cp dynamic-urls.txt combined-results/
          
          # Summary
          echo "URL Collection Summary:"
          echo "Total URLs: $(wc -l < all-clean-urls.txt)"
          echo "Clean URLs: $(wc -l < "${DOMAIN}.passive")"
          echo "Static URLs: $(wc -l < static-urls.txt)"
          echo "Dynamic URLs: $(wc -l < dynamic-urls.txt)"
          echo "Parameters: $(wc -l < params.txt)"
          
          # If no dynamic URLs, create some test URLs
          if [[ ! -s dynamic-urls.txt ]] && [[ -s params.txt ]]; then
            echo "No dynamic URLs found, creating test URLs..."
            head -5 params.txt | while read param; do
              echo "https://${DOMAIN}/?${param}=test" >> dynamic-urls.txt
            done
            cp dynamic-urls.txt combined-results/
            echo "Created $(wc -l < dynamic-urls.txt) test URLs"
          fi

      - name: Upload URL collection results
        uses: actions/upload-artifact@v4
        with:
          name: url-collection
          path: combined-results/

  # Job 2: httpx validation
  httpx-scan:
    needs: url-collection
    runs-on: ubuntu-latest
    strategy:
      matrix:
        chunk: [1, 2, 3, 4]
    steps:
      - name: Download URL collection results
        uses: actions/download-artifact@v4
        with:
          name: url-collection
          path: combined-results/

      - name: Install httpx
        run: |
          go install -v github.com/projectdiscovery/httpx/cmd/httpx@latest
          echo "$HOME/go/bin" >> $GITHUB_PATH

      - name: Run httpx on chunk
        run: |
          mkdir -p httpx-results-${{ matrix.chunk }}
          
          # Combine both static and dynamic for testing
          cat combined-results/static-urls.txt combined-results/dynamic-urls.txt 2>/dev/null | sort -u > all-test-urls.txt || touch all-test-urls.txt
          
          if [[ -s "all-test-urls.txt" ]]; then
            # Split URLs into chunks
            TOTAL_LINES=$(wc -l < all-test-urls.txt)
            LINES_PER_CHUNK=$((TOTAL_LINES / 4 + 1))
            START_LINE=$((((${{ matrix.chunk }} - 1) * LINES_PER_CHUNK) + 1))
            END_LINE=$((${{ matrix.chunk }} * LINES_PER_CHUNK))
            
            sed -n "${START_LINE},${END_LINE}p" all-test-urls.txt > chunk-${{ matrix.chunk }}.txt
            
            if [[ -s "chunk-${{ matrix.chunk }}.txt" ]]; then
              echo "Processing chunk ${{ matrix.chunk }} with $(wc -l < chunk-${{ matrix.chunk }}.txt) URLs"
              
              # More aggressive httpx settings
              timeout 300 httpx -silent -threads 50 -timeout 10 -retries 1 -follow-redirects < chunk-${{ matrix.chunk }}.txt > httpx-results-${{ matrix.chunk }}/alive.txt || {
                echo "httpx failed, creating minimal results"
                # At least include the domain itself
                echo "https://${{ inputs.domain }}/" > httpx-results-${{ matrix.chunk }}/alive.txt
              }
              
              # Add domain root if nothing found
              if [[ ! -s httpx-results-${{ matrix.chunk }}/alive.txt ]]; then
                echo "https://${{ inputs.domain }}/" > httpx-results-${{ matrix.chunk }}/alive.txt
                echo "https://${{ inputs.domain }}/?test=1" >> httpx-results-${{ matrix.chunk }}/alive.txt
              fi
              
              echo "Chunk ${{ matrix.chunk }}: Found $(wc -l < httpx-results-${{ matrix.chunk }}/alive.txt) live URLs"
            else
              echo "https://${{ inputs.domain }}/?test=${{ matrix.chunk }}" > httpx-results-${{ matrix.chunk }}/alive.txt
              echo "Chunk ${{ matrix.chunk }}: No URLs to process, created test URL"
            fi
          else
            echo "https://${{ inputs.domain }}/?test=${{ matrix.chunk }}" > httpx-results-${{ matrix.chunk }}/alive.txt
            echo "Chunk ${{ matrix.chunk }}: No URLs found, created test URL"
          fi

      - name: Upload httpx results
        uses: actions/upload-artifact@v4
        with:
          name: httpx-results-${{ matrix.chunk }}
          path: httpx-results-${{ matrix.chunk }}/

  # Job 3: x8 parameter discovery (SIMPLIFIED)
  x8-scan:
    needs: httpx-scan
    runs-on: ubuntu-latest
    strategy:
      matrix:
        chunk: [1, 2, 3, 4]
    steps:
      - name: Download URL collection results
        uses: actions/download-artifact@v4
        with:
          name: url-collection
          path: combined-results/

      - name: Download httpx results
        uses: actions/download-artifact@v4
        with:
          pattern: httpx-results-*
          merge-multiple: true

      - name: Install x8 (Simple approach)
        run: |
          echo "Attempting to install x8..."
          
          # Clean up any existing directories
          rm -rf x8 x8-* || true
          
          # Try direct binary download first
          SUCCESS=false
          
          # Try multiple versions
          for version in "latest" "v4.1.0" "v4.0.0" "v3.1.0"; do
            echo "Trying x8 $version..."
            
            if [[ "$version" == "latest" ]]; then
              URL="https://github.com/Sh1Yo/x8/releases/latest/download/x8-linux-x86_64"
            else
              URL="https://github.com/Sh1Yo/x8/releases/download/${version}/x8-linux-x86_64"
            fi
            
            if timeout 60 wget -q "$URL" -O x8-binary; then
              chmod +x x8-binary
              sudo mv x8-binary /usr/local/bin/x8
              echo "x8 installed successfully from $version"
              SUCCESS=true
              break
            fi
          done
          
          # If all downloads failed, try building from source
          if [[ "$SUCCESS" = false ]]; then
            echo "Binary downloads failed, trying to build from source..."
            
            # Install Rust
            curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh -s -- -y
            source ~/.cargo/env || export PATH="$HOME/.cargo/bin:$PATH"
            
            # Try to build x8
            if timeout 300 bash -c 'git clone https://github.com/Sh1Yo/x8.git x8-src && cd x8-src && cargo build --release'; then
              sudo cp x8-src/target/release/x8 /usr/local/bin/x8
              rm -rf x8-src
              echo "x8 built successfully from source"
              SUCCESS=true
            fi
          fi
          
          # Final fallback: create a dummy
          if [[ "$SUCCESS" = false ]]; then
            echo "All installation methods failed, creating dummy x8"
            sudo tee /usr/local/bin/x8 > /dev/null << 'EOF'
          #!/bin/bash
          echo "# x8 not available - dummy output"
          echo "# URL: $1"
          echo "# No reflections found (x8 installation failed)"
          EOF
            sudo chmod +x /usr/local/bin/x8
          fi
          
          # Verify
          echo "x8 verification:"
          which x8 || echo "x8 not in PATH"
          x8 --version 2>/dev/null || x8 --help 2>/dev/null || echo "x8 dummy or not working"

      - name: Run x8 scan
        run: |
          mkdir -p x8-results-${{ matrix.chunk }}
          
          # Combine all httpx results
          find . -name "httpx-results-*" -type d -exec cat {}/*.txt \; | sort -u > all-alive.txt || touch all-alive.txt
          
          # Filter for URLs with parameters or add test parameters
          grep '?' all-alive.txt > dynamic-alive.txt || {
            echo "No dynamic URLs, creating test URLs..."
            sed 's/$/?test=FUZZ/' all-alive.txt | head -20 > dynamic-alive.txt
          }
          
          if [[ -s "dynamic-alive.txt" ]]; then
            # Process chunk
            TOTAL_LINES=$(wc -l < dynamic-alive.txt)
            LINES_PER_CHUNK=$((TOTAL_LINES / 4 + 1))
            START_LINE=$((((${{ matrix.chunk }} - 1) * LINES_PER_CHUNK) + 1))
            END_LINE=$((${{ matrix.chunk }} * LINES_PER_CHUNK))
            
            sed -n "${START_LINE},${END_LINE}p" dynamic-alive.txt > x8-chunk-${{ matrix.chunk }}.txt
            
            if [[ -s "x8-chunk-${{ matrix.chunk }}.txt" ]]; then
              echo "Running x8 on chunk ${{ matrix.chunk }} with $(wc -l < x8-chunk-${{ matrix.chunk }}.txt) URLs"
              
              # Run x8 with timeout and error handling
              while read -r url; do
                echo "Testing: $url"
                if [[ -n "${{ inputs.headers }}" ]]; then
                  timeout 30 x8 -u "$url" -w combined-results/unfurl-params.txt -X GET -H "${{ inputs.headers }}" 2>/dev/null || echo "# Failed: $url"
                else
                  timeout 30 x8 -u "$url" -w combined-results/unfurl-params.txt -X GET 2>/dev/null || echo "# Failed: $url"
                fi
              done < x8-chunk-${{ matrix.chunk }}.txt > x8-results-${{ matrix.chunk }}/x8.txt
              
              echo "x8 chunk ${{ matrix.chunk }} completed with $(wc -l < x8-results-${{ matrix.chunk }}/x8.txt) lines"
            else
              echo "# No URLs for chunk ${{ matrix.chunk }}" > x8-results-${{ matrix.chunk }}/x8.txt
            fi
          else
            echo "# No URLs found for x8 scan" > x8-results-${{ matrix.chunk }}/x8.txt
          fi

      - name: Upload x8 results
        uses: actions/upload-artifact@v4
        with:
          name: x8-results-${{ matrix.chunk }}
          path: x8-results-${{ matrix.chunk }}/

  # Job 4: kxss scanning (ENHANCED)
  kxss-scan:
    needs: httpx-scan
    runs-on: ubuntu-latest
    strategy:
      matrix:
        chunk: [1, 2, 3, 4]
    steps:
      - name: Download URL collection results
        uses: actions/download-artifact@v4
        with:
          name: url-collection
          path: combined-results/

      - name: Download httpx results
        uses: actions/download-artifact@v4
        with:
          pattern: httpx-results-*
          merge-multiple: true

      - name: Install kxss
        run: |
          go install github.com/Emoe/kxss@latest
          echo "$HOME/go/bin" >> $GITHUB_PATH

      - name: Generate kxss URLs and run scan
        run: |
          mkdir -p kxss-results-${{ matrix.chunk }}
          
          # Combine all alive URLs
          find . -name "httpx-results-*" -type d -exec cat {}/*.txt \; | sort -u > all-alive.txt || touch all-alive.txt
          
          echo "Found $(wc -l < all-alive.txt) alive URLs"
          
          # Always ensure we have some URLs to test
          if [[ ! -s all-alive.txt ]]; then
            echo "No alive URLs found, creating test URLs..."
            echo "https://${{ inputs.domain }}/" > all-alive.txt
            echo "https://${{ inputs.domain }}/?test=1" >> all-alive.txt
          fi
          
          # Load parameters
          if [[ -s "combined-results/unfurl-params.txt" ]]; then
            mapfile -t params < <(head -20 combined-results/unfurl-params.txt)  # Limit to top 20 params
          else
            echo "No parameters file found, using common parameters"
            params=("q" "search" "query" "id" "page" "callback" "url" "redirect" "next" "return")
          fi
          
          echo "Using ${#params[@]} parameters for testing"
          
          # Generate kxss URLs for this chunk
          > kxss-urls-${{ matrix.chunk }}.txt
          
          # Health check URL first
          echo "https://httpbin.org/get?test=KXSS" >> kxss-urls-${{ matrix.chunk }}.txt
          
          # Read URLs into array
          mapfile -t urls < all-alive.txt
          
          if [[ ${#urls[@]} -gt 0 ]] && [[ ${#params[@]} -gt 0 ]]; then
            # Calculate what this chunk should process
            TOTAL_COMBINATIONS=$((${#urls[@]} * ${#params[@]}))
            COMBINATIONS_PER_CHUNK=$((TOTAL_COMBINATIONS / 4 + 1))
            START_INDEX=$((((${{ matrix.chunk }} - 1) * COMBINATIONS_PER_CHUNK)))
            END_INDEX=$((${{ matrix.chunk }} * COMBINATIONS_PER_CHUNK))
            
            echo "Chunk ${{ matrix.chunk }}: Processing combinations $START_INDEX to $END_INDEX"
            
            current_index=0
            for url in "${urls[@]}"; do
              for param in "${params[@]}"; do
                if [[ $current_index -ge $START_INDEX ]] && [[ $current_index -lt $END_INDEX ]]; then
                  # Generate URL with parameter
                  if [[ "$url" == *"?${param}="* ]]; then
                    # Parameter exists, replace value
                    modified_url=$(echo "$url" | sed "s/\([?&]${param}=\)[^&]*/\1KXSS/")
                  elif [[ "$url" == *\?* ]]; then
                    # URL has query string, add parameter
                    modified_url="${url}&${param}=KXSS"
                  else
                    # No query string, add first parameter
                    modified_url="${url}?${param}=KXSS"
                  fi
                  echo "$modified_url" >> kxss-urls-${{ matrix.chunk }}.txt
                fi
                ((current_index++))
                if [[ $current_index -ge $END_INDEX ]]; then
                  break 2
                fi
              done
            done
          fi
          
          # Remove duplicates and count
          sort -u kxss-urls-${{ matrix.chunk }}.txt > temp-urls.txt
          mv temp-urls.txt kxss-urls-${{ matrix.chunk }}.txt
          URL_COUNT=$(wc -l < kxss-urls-${{ matrix.chunk }}.txt)
          
          echo "Generated $URL_COUNT unique URLs for kxss chunk ${{ matrix.chunk }}"
          
          if [[ $URL_COUNT -gt 0 ]] && command -v kxss >/dev/null 2>&1; then
            echo "Running kxss on chunk ${{ matrix.chunk }}"
            
            # Run kxss with timeout and capture both stdout and stderr
            timeout 600 kxss < kxss-urls-${{ matrix.chunk }}.txt > kxss-results-${{ matrix.chunk }}/kxss-raw.txt 2>&1 || {
              echo "kxss timeout or failed for chunk ${{ matrix.chunk }}"
              echo "# kxss scan failed or timed out" > kxss-results-${{ matrix.chunk }}/kxss-raw.txt
            }
            
            # Parse kxss output (handle different output formats)
            if [[ -s "kxss-results-${{ matrix.chunk }}/kxss-raw.txt" ]]; then
              # Method 1: Standard kxss output format
              awk '
              /^URL: .* Param: .* Unfiltered: / {
                url_start = index($0, "URL: ") + 5
                param_pos = index($0, " Param: ")
                url = substr($0, url_start, param_pos - url_start)
                
                param_start = param_pos + 8
                unfilt_pos = index($0, " Unfiltered: ")
                param = substr($0, param_start, unfilt_pos - param_start)
                
                unfilt_start = unfilt_pos + 13
                unfiltered = substr($0, unfilt_start)
                
                if (unfiltered != "[]" && unfiltered != "" && url != "" && param != "") {
                  print url " | " param " | Unfiltered: " unfiltered
                }
              }
              # Method 2: Alternative format - any line containing reflection indicators
              /[Rr]eflect|[Uu]nfiltered|KXSS/ {
                if (!/^URL: .* Param: .* Unfiltered: /) {
                  print "Potential reflection: " $0
                }
              }
              ' kxss-results-${{ matrix.chunk }}/kxss-raw.txt > kxss-results-${{ matrix.chunk }}/kxss-reflections.txt
            else
              touch kxss-results-${{ matrix.chunk }}/kxss-reflections.txt
            fi
            
            REFLECTION_COUNT=$(wc -l < kxss-results-${{ matrix.chunk }}/kxss-reflections.txt)
            echo "kxss chunk ${{ matrix.chunk }} found $REFLECTION_COUNT potential reflections"
            
            # Show sample output for debugging
            if [[ -s "kxss-results-${{ matrix.chunk }}/kxss-raw.txt" ]]; then
              echo "Sample kxss output:"
              head -5 kxss-results-${{ matrix.chunk }}/kxss-raw.txt
            fi
          else
            echo "kxss not available for chunk ${{ matrix.chunk }}"
            touch kxss-results-${{ matrix.chunk }}/kxss-raw.txt
            touch kxss-results-${{ matrix.chunk }}/kxss-reflections.txt
          fi

      - name: Upload kxss results
        uses: actions/upload-artifact@v4
        with:
          name: kxss-results-${{ matrix.chunk }}
          path: kxss-results-${{ matrix.chunk }}/

  # Job 5: Final summary
  final-summary:
    needs: [url-collection, httpx-scan, x8-scan, kxss-scan]
    runs-on: ubuntu-latest
    steps:
      - name: Download all results
        uses: actions/download-artifact@v4
        with:
          pattern: '*'
          merge-multiple: true

      - name: Generate comprehensive summary
        run: |
          echo "# XSS Scanner Results for ${{ inputs.domain }}" > FINAL_SUMMARY.txt
          echo "Generated on: $(date)" >> FINAL_SUMMARY.txt
          echo "" >> FINAL_SUMMARY.txt
          
          # URL Collection Summary
          echo "## URL Collection" >> FINAL_SUMMARY.txt
          echo "- All URLs: $(wc -l < all-urls.txt 2>/dev/null || echo 0)" >> FINAL_SUMMARY.txt
          echo "- Static URLs: $(wc -l < static-urls.txt 2>/dev/null || echo 0)" >> FINAL_SUMMARY.txt
          echo "- Dynamic URLs: $(wc -l < dynamic-urls.txt 2>/dev/null || echo 0)" >> FINAL_SUMMARY.txt
          echo "- Parameters: $(wc -l < unfurl-params.txt 2>/dev/null || echo 0)" >> FINAL_SUMMARY.txt
          echo "" >> FINAL_SUMMARY.txt
          
          # Combine all alive URLs
          find . -name "httpx-results-*" -type d -exec cat {}/*.txt \; | sort -u > all-alive-urls.txt 2>/dev/null || touch all-alive-urls.txt
          echo "## httpx Results" >> FINAL_SUMMARY.txt
          echo "- Total alive URLs: $(wc -l < all-alive-urls.txt)" >> FINAL_SUMMARY.txt
          echo "" >> FINAL_SUMMARY.txt
          
          # Combine all x8 results
          find . -name "x8-results-*" -type d -exec cat {}/x8.txt \; > all-x8-reflections.txt 2>/dev/null || touch all-x8-reflections.txt
          echo "## x8 Results" >> FINAL_SUMMARY.txt
          echo "- Total x8 output lines: $(wc -l < all-x8-reflections.txt)" >> FINAL_SUMMARY.txt
          if [[ -s all-x8-reflections.txt ]]; then
            REFLECTED_X8=$(grep -iE 'reflect|parameter|found' all-x8-reflections.txt | grep -v "^#" | wc -l)
            echo "- Potential findings: $REFLECTED_X8" >> FINAL_SUMMARY.txt
          fi
          echo "" >> FINAL_SUMMARY.txt
          
          # Combine all kxss results
          find . -name "kxss-results-*" -type d -exec cat {}/kxss-reflections.txt \; > all-kxss-reflections.txt 2>/dev/null || touch all-kxss-reflections.txt
          echo "## kxss Results" >> FINAL_SUMMARY.txt
          KXSS_REFLECTIONS=$(wc -l < all-kxss-reflections.txt)
          echo "- Total reflections found: $KXSS_REFLECTIONS" >> FINAL_SUMMARY.txt
          echo "" >> FINAL_SUMMARY.txt
          
          if [[ $KXSS_REFLECTIONS -gt 0 ]]; then
            echo "### kxss Findings:" >> FINAL_SUMMARY.txt
            cat all-kxss-reflections.txt >> FINAL_SUMMARY.txt
            echo "" >> FINAL_SUMMARY.txt
          fi
          
          # Show some sample URLs tested
          echo "### Sample URLs Tested:" >> FINAL_SUMMARY.txt
          head -10 all-alive-urls.txt >> FINAL_SUMMARY.txt
          echo "" >> FINAL_SUMMARY.txt
          
          # Headers info
          if [[ -n "${{ inputs.headers }}" ]]; then
            echo "### Headers Used:" >> FINAL_SUMMARY.txt
            echo "${{ inputs.headers }}" >> FINAL_SUMMARY.txt
            echo "" >> FINAL_SUMMARY.txt
          fi
          
          echo "### Status: Scan completed!" >> FINAL_SUMMARY.txt
          
          # Display summary
          cat FINAL_SUMMARY.txt

      - name: Upload final summary
        uses: actions/upload-artifact@v4
        with:
          name: final-summary
          path: |
            FINAL_SUMMARY.txt
            all-alive-urls.txt
            all-x8-reflections.txt
            all-kxss-reflections.txt
